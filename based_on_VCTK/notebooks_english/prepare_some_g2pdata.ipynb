{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'files_len' (int)\n",
      "shape_files_words_len (2,)\n",
      "Stored 'files_words_len' (list)\n",
      "shape_words_final: (14, 7)\n",
      "shape_words_len_final: (14,)\n",
      "words_final: [[25, 21, 12, 9, 26, 12, 0], [10, 9, 21, 21, 0, 0, 0], [26, 29, 12, 21, 21, 9, 4], [9, 26, 18, 0, 0, 0, 0], [17, 12, 27, 0, 0, 0, 0], [29, 22, 0, 0, 0, 0, 0], [11, 27, 16, 23, 14, 0, 0], [29, 17, 12, 26, 12, 0, 0], [29, 17, 16, 23, 14, 26, 0], [30, 16, 29, 17, 0, 0, 0], [17, 12, 27, 0, 0, 0, 0], [15, 27, 22, 20, 0, 0, 0], [29, 17, 12, 0, 0, 0, 0], [26, 29, 22, 27, 12, 4, 0]]\n",
      "words_len_final: [6, 4, 7, 3, 3, 2, 5, 5, 6, 4, 3, 4, 3, 6]\n",
      "files_words_len [3, 11]\n",
      "<type 'list'> <type 'list'>\n",
      "Stored 'words_final2' (list)\n",
      "Stored 'words_len_final2' (list)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import pickle\n",
    "import sys\n",
    "import fnmatch\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "def find_files(directory, pattern='*.txt'):\n",
    "    '''Recursively finds all files matching the pattern.'''\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "#files=find_files(\"/home/VCTK-Corpus/txt/p225\")\n",
    "files=find_files(\"/home/VCTK-Corpus/txt/2tfiles\")\n",
    "files_len=len(files)\n",
    "%store files_len\n",
    "metadata_file = \"../../deepvoice2/cmu/cmu.pkl\"\n",
    "train_file = \"../../deepvoice2/cmu/cmu_data.npz\"\n",
    "directory=\"../../deepvoice2/cmu\"\n",
    "with open(metadata_file, \"r\") as read_file:\n",
    "    meta = pickle.load(read_file)\n",
    "char2id = meta[\"char2id\"]\n",
    "id2char = meta[\"id2char\"]\n",
    "phoneme2id = meta[\"phoneme2id\"]\n",
    "id2phoneme = meta[\"id2phoneme\"]\n",
    "\n",
    "input_vocab_size = len(char2id)\n",
    "output_vocab_size= len(phoneme2id)\n",
    "\n",
    "end_token = phoneme2id[\"<eos>\"]\n",
    "files_words=[]\n",
    "files_words_len=[]\n",
    "for file in files:\n",
    "    for line in open(file,'r').readlines(): \n",
    "            #words= line.lower().strip().split(' ')\n",
    "            words= line.lower().replace(',','').replace('?','').strip().split(' ')\n",
    "            words=np.array(list(words))\n",
    "            files_words_len.append(len(words))\n",
    "            files_words.append(list(words))\n",
    "            \n",
    "            #print files_words\n",
    "#print \"files_words:\",files_words,\"shape_files_words:\",np.shape(files_words) #231\n",
    "print \"shape_files_words_len\",np.shape(files_words_len)\n",
    "%store files_words_len\n",
    "#print len(files_words[0][0])\n",
    "words_len = np.array([[len(word) for word in words] for words in files_words])\n",
    "#print \"words_len:\",words_len,\"shape_words_len:\",np.shape(words_len)# 2772\n",
    "max_each_len=[]\n",
    "for i in range(len(words_len)):\n",
    "    max_each_len.append(np.amax(words_len[i]))\n",
    "max_words_len = np.amax(max_each_len)\n",
    "#print \"max_words_len\",max_words_len\n",
    "#max_words_len=8\n",
    "#print \"files_words:\",np.shape(files_words)\n",
    "#print len(files_words[0]),len(files_words[0][0]),files_words\n",
    "files_words = [[[char2id[ch] for ch in word] for word in words ]for words in files_words]\n",
    "#print \"files_words\",files_words,\"shape_files_words\",np.shape(files_words)#2772\\\n",
    "#print files_words[0][0]\n",
    "files_words = np.array([[np.pad(np.array(word), (0, max_words_len - len(word)), 'constant', constant_values=(0, 0)) for word in words]for words in files_words])\n",
    "for i in range(len(files_words)):\n",
    "    for j in range(len(files_words[i])):\n",
    "        files_words[i][j]=list(files_words[i][j])\n",
    "files_words=list(files_words)\n",
    "words_final=[]\n",
    "words_len_final=[]\n",
    "for i in range(len(files_words)):\n",
    "    for j in range(len(files_words[i])):\n",
    "        words_final.append(files_words[i][j])\n",
    "        words_len_final.append(words_len[i][j])\n",
    "\n",
    "#words_len=list(words_len)\n",
    "print \"shape_words_final:\",np.shape(words_final)\n",
    "print \"shape_words_len_final:\",np.shape(words_len_final)\n",
    "\n",
    "print \"words_final:\",words_final\n",
    "print \"words_len_final:\",words_len_final\n",
    "print \"files_words_len\",files_words_len\n",
    "print type(words_final),type(words_len_final)\n",
    "np.savez(os.path.join(directory, 'VCTK_data'), X=words_final, X_seq_len=words_len_final)\n",
    "#%store words_final\n",
    "#%store words_len_final\n",
    "words_final2=words_final\n",
    "words_len_final2=words_len_final\n",
    "%store words_final2\n",
    "%store words_len_final2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
