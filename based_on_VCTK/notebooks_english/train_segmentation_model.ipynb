{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"/home/VCTK-Corpus/wav48/p225\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from models.segmentation_model import SegmentationModel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import fnmatch\n",
    "import librosa\n",
    "import itertools \n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_parameters = {\n",
    "    \"lr\": 0.001,\n",
    "    \"decay_steps\": 400,\n",
    "    \"decay_rate\": 0.95,\n",
    "    \"dropout_prob\": 0.05\n",
    "}\n",
    "\n",
    "model_parameters = {\n",
    "    \"speaker_embedding_size\": 16,#\n",
    "    \"num_conv_layers\": 2,\n",
    "    \"conv_num_filters\": 8,\n",
    "    \"conv_kernel_size\": [2, 2],\n",
    "    \"num_bidirectional_units\":16 ,#16\n",
    "    \"num_bidirectional_layers\": 2,\n",
    "}\n",
    "\n",
    "output_vocab_size=5626 #3, 29 \n",
    "num_speakers = 10 #10\n",
    "num_steps = 2\n",
    "save_energy = 2\n",
    "n_mels = 20\n",
    "num_beams = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-317.97035132, -320.02675131, -320.49495957, ..., -315.87566673,\n",
      "        -306.33839905, -257.33849693],\n",
      "       [   6.82147203,    5.26051038,    5.43182948, ...,   12.73368223,\n",
      "          23.06505468,   42.16068284],\n",
      "       [   9.09845288,    6.68798967,    6.17807009, ...,   12.46905171,\n",
      "          20.09967125,   25.53372145],\n",
      "       ..., \n",
      "       [   5.00629905,    5.22212353,    5.08337967, ...,    4.68425215,\n",
      "           3.78057042,   -1.52735552],\n",
      "       [   4.70851533,    5.36507338,    4.96346314, ...,    4.61364601,\n",
      "           5.37753316,    1.14885334],\n",
      "       [   5.69843531,    5.74431946,    5.2694922 , ...,    4.50123533,\n",
      "           8.12088201,    9.15983976]]), array([[-310.33822486, -309.71954486, -309.78283067, ..., -312.52741107,\n",
      "        -307.24111342, -271.89655562],\n",
      "       [   9.52933323,   10.77399375,   10.83669568, ...,    6.58462739,\n",
      "          13.47175379,   36.30191069],\n",
      "       [   9.90469798,   10.82214386,   10.77172059, ...,    6.78209292,\n",
      "          12.44567716,   23.71583229],\n",
      "       ..., \n",
      "       [   4.97664171,    5.48934378,    5.35308758, ...,    6.15850216,\n",
      "           6.01763775,   -0.87092418],\n",
      "       [   5.17023611,    4.92473488,    4.97522726, ...,    5.94441808,\n",
      "           7.35953218,    3.50011343],\n",
      "       [   4.47562937,    4.67779082,    4.56286111, ...,    5.68000938,\n",
      "           8.20712762,    6.88086233]])]\n",
      "20\n",
      "203\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 32)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 16)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 32)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 16)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 32)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 16)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 32)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 16)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 32)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 16)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 32)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 16)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 32)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 16)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 32)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 16)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 32)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 16)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 32)\n",
      "total_arg_size 160\n",
      "total_arg_size 176\n",
      "shape_w (176, 16)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 32)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 16)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 32)\n",
      "total_arg_size 32\n",
      "total_arg_size 48\n",
      "shape_w (48, 16)\n",
      "(2, 401, 20)\n",
      "(2,)\n",
      "()\n",
      "INFO:tensorflow:Restoring parameters from ../weights/train_grapheme_to_phoneme_model_notebook/model2.ckpt-2\n",
      "index_model4: (2, 401) [[72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 72 31 31\n",
      "  31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 17 31 17 31 17\n",
      "  73 73 31 73 31 73 31 31 31 31 31 31 31 31 31 31 31  1 73 73 73 73 73 73\n",
      "  73 34 73 34 73 34 73 34 73  1 73 29 73 29 73 29 73 29 73 29 73 29 73 29\n",
      "  73 29 73 29 73 29 73 29  1 29 34 29 34 34 34 34 34 34 34 34 34 34 34  1\n",
      "  34 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73\n",
      "  73 73 73 73 73 73 73 73 10 10 10 10 10  1 10  8 49  1 21 21 21 49 21  1\n",
      "  21 48 21 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48  6 48  6 48\n",
      "   6 48  6 48  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7]\n",
      " [ 4 14 14 14 14 14 14 73 14 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73\n",
      "  73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73 73\n",
      "  73 73 73 73 73 73 73 73 73 48 48 73 48  1 48 14 48 14 48 14 48 14 48 14\n",
      "  48 14 48 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14  1\n",
      "  14 14 14 14 14 14 14 14 14 14 14 14 14  1 14 36 14 36 36 36 36 36 36 36\n",
      "  36 36 36 36 36 36 36 36 36 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      "  34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34  1 34 34  1  1 34 31 34\n",
      "  31 34 31  1 31 18 18 34 18 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      "  34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      "  34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      "  34 34  1 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      "  34 34 34 34 34 34 34 34 34 34 34 34 34 34  1 23 34 23 34 34 34 34 34 34\n",
      "  34 34 34 34 34 34 34 34 23 34 73 73 73 73 73  1 73 34 73 34 73 34 73 34\n",
      "  73 34 73  1 73  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "   7  7  7  7  7  7  7  7  7  1 48  6 48  6 48  6 48  6 48  6 48  6 48  6\n",
      "  48  6 48  6 48  6 48  6 48  6 48  6 48  6 48  6 48  6 48  6 48  6 48  6\n",
      "  48  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6]]\n",
      "duration_buckets is [[2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10], [10, 10, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] shape_duration_buckets is (2,)\n",
      "voiced_target: <type 'list'> [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Stored 'yinsu' (list)\n",
      "Stored 'yinsu_seq_len' (list)\n",
      "Stored 'duration_buckets' (list)\n",
      "Stored 'index_model4' (ndarray)\n",
      "Stored 'voiced_target' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_files(directory, pattern='*.wav'):\n",
    "    '''Recursively finds all files matching the pattern.'''\n",
    "    files = []\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "\n",
    "files=find_files(\"/home/VCTK-Corpus/wav48/2wfiles\")\n",
    "#files=find_files(\"/home/VCTK-Corpus/wav48/p225\")\n",
    "melM=[]\n",
    "\n",
    "from scipy.io import wavfile\n",
    "for file in files:\n",
    "#    print file\n",
    "    \n",
    "    #sample_rate, X = wavfile.read(file)\n",
    "    X, sr = librosa.load(file,sr=50500)\n",
    "    melM.append(librosa.feature.mfcc(X,sr=100,n_mfcc=20))\n",
    "%store -r files_len\n",
    "#231\n",
    "#files_len=files_len\n",
    "files_len=2\n",
    "print melM\n",
    "print len(melM[0])\n",
    "print len(melM[0][0])\n",
    "file_len = np.array([len(melM[i][0]) for i in range(files_len)], dtype=np.int32)\n",
    "max_file_len = np.amax(file_len)\n",
    "#print max_file_len\n",
    "melM = [[list(np.pad(np.array(melM[i][j], dtype=np.float32),\n",
    "                     (0, max_file_len - file_len[i]), \n",
    "                     'constant', constant_values=(0, 0)))\n",
    "         for j in range(20)] for i in range(files_len)]\n",
    "melM=np.array(melM).transpose(0,2,1)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    model = SegmentationModel(\n",
    "        output_vocab_size, num_speakers, model_parameters,\n",
    "    )\n",
    "    \n",
    "    frequencies = tf.placeholder(tf.float32, [None, None, n_mels])\n",
    "    frequencies_seq_len = tf.placeholder(tf.int32, [None])\n",
    "    speaker_ids = tf.placeholder(tf.int32, [None])\n",
    "    phonemes = tf.sparse_placeholder(tf.int32)\n",
    "    \n",
    "    \n",
    "    train_op_tf, loss_tf, global_step_tf, summary_tf = model.build_train_operations(\n",
    "        frequencies, frequencies_seq_len,\n",
    "        speaker_ids,\n",
    "        phonemes,\n",
    "        train_parameters\n",
    "    )\n",
    "    \n",
    "    predictor_frequencies = tf.placeholder(tf.float32, [None, None, n_mels])\n",
    "    predictor_frequencies_seq_len = tf.placeholder(tf.int32, [None])\n",
    "    predictor_speaker_ids = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    greedy_predictor_tf = model.build_greedy_predictor(\n",
    "        predictor_frequencies, predictor_frequencies_seq_len, predictor_speaker_ids, True\n",
    "    )\n",
    "    \n",
    "    encoder_output,beam_predictor_tf = model.build_beam_search_predictor(\n",
    "        predictor_frequencies, predictor_frequencies_seq_len, predictor_speaker_ids,\n",
    "        num_beams, True\n",
    "    )\n",
    "\n",
    "    train_writer = tf.summary.FileWriter('../log/train_grapheme_to_phoneme_model_notebook/train', sess.graph)\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=3, keep_checkpoint_every_n_hours=3)\n",
    "    %store -r target_indices\n",
    "    %store -r target_values\n",
    "    %store -r dense_shape\n",
    "    \n",
    "    print np.shape(melM)\n",
    "    print np.shape(np.array([file_len[i]for i in range(files_len)],dtype=np.float))\n",
    "    print np.shape(files_len)\n",
    "    #print np.shape()\n",
    "    train=1\n",
    "    if train==0:\n",
    "        for _ in xrange(num_steps):\n",
    "\n",
    "    #         target_indices=[[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2]]\n",
    "    #         target_values=[1, 2, 3, 4, 5, 6]\n",
    "    #         dense_shape=[2, 4\n",
    "    #       target_indices=[[0,0],[0,1],[0,2],[1,0],[1,1],[1,2]]\n",
    "    #       target_values=[1,2,3,4,5,6]\n",
    "    #       dense_shape=[2,3]\n",
    "            \n",
    "\n",
    "            out = sess.run([\n",
    "                train_op_tf,\n",
    "                global_step_tf,\n",
    "                loss_tf,\n",
    "                summary_tf\n",
    "            ], feed_dict={\n",
    "                frequencies:melM,#231,1232,20\n",
    "                frequencies_seq_len: np.array([file_len[i] for i in range(files_len)],dtype=np.float32),#1232*np.ones(231),\n",
    "                speaker_ids: 1 * np.ones(files_len),\n",
    "                phonemes:(target_indices,target_values, dense_shape)\n",
    "            })\n",
    "            #17* np.ones(1),\n",
    "            #k个文件speaker的编号\n",
    "    # feed_dict={\n",
    "    #             frequencies: np.random.rand(2, 10, 20),\n",
    "    #             frequencies_seq_len: 8* np.ones(2),\n",
    "    #             speaker_ids: 2 * np.ones((2)),\n",
    "    #             phonemes:(target_indices,target_values, dense_shape)\n",
    "    #         })\n",
    "            _, global_step, loss, summary  = out\n",
    "\n",
    "            print global_step\n",
    "            print loss\n",
    "\n",
    "            train_writer.add_summary(summary, global_step)\n",
    "\n",
    "            # detect gradient explosion\n",
    "            if loss > 1e8 and global_step > 500:\n",
    "                print('loss exploded')\n",
    "                break\n",
    "\n",
    "            if global_step % save_energy == 0 and global_step != 0:\n",
    "\n",
    "                print('saving weights')\n",
    "                if not os.path.exists('../weights/train_grapheme_to_phoneme_model_notebook'):\n",
    "                    os.makedirs('../weights/train_grapheme_to_phoneme_model_notebook')\n",
    "                saver.save(sess, '../weights/train_grapheme_to_phoneme_model_notebook/model2.ckpt', global_step=global_step)\n",
    "    \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    else:\n",
    "        saver.restore(sess, '../weights/train_grapheme_to_phoneme_model_notebook/model2.ckpt-2')\n",
    "        graph = tf.get_default_graph()\n",
    "        \n",
    "#         beam_predictor_tf = model.build_beam_search_predictor(\n",
    "#         predictor_frequencies, predictor_frequencies_seq_len, predictor_speaker_ids,\n",
    "#         num_beams, True\n",
    "#     )\n",
    "        \n",
    "        encoder_output,beam_predictor=sess.run([encoder_output,beam_predictor_tf],feed_dict={predictor_frequencies:melM,\n",
    "                                                               predictor_frequencies_seq_len:np.array([file_len[i]for i in range(files_len)],dtype=np.float32),\n",
    "                                                               predictor_speaker_ids:2 * np.ones((files_len)),\n",
    "                                                               \n",
    "                                                               })\n",
    "        ###############\n",
    "        ###############\n",
    "        q=encoder_output\n",
    "        beamsize=3\n",
    "        x,y,z=np.shape(encoder_output)\n",
    "        #print x,y,z\n",
    "\n",
    "        index3=[[[0 for i in range(beamsize)] for j in range(y)]for k in range(x)]\n",
    "        BEAM3=[[[0 for i in range(beamsize)] for j in range(y)]for k in range(x)]\n",
    "        #print np.shape(index3)\n",
    "        #p=np.array([[5,2,4,6],[3,7,4,5],[9,1,10,3]])\n",
    "        #p=np.random.rand(3,4)\n",
    "        for t in range(x):\n",
    "            #print \"t is:\",t\n",
    "            p=q[t]\n",
    "            b,c=y,z\n",
    "\n",
    "            index=[[0 for i in range(beamsize)] for j in range(b)]\n",
    "            mask=[[0 for i in range(beamsize)] for j in range(b)]\n",
    "            index2=[[0 for i in range(beamsize)] for j in range(b)]\n",
    "\n",
    "            states_1=p[0,:]#embedding_size\n",
    "            index_states_1=np.argsort(states_1)\n",
    "            BEAM=[]\n",
    "            BEAM2=[[0 for i in range(beamsize)] for j in range(b)]#b,beamsize\n",
    "            for i in range(beamsize):\n",
    "                BEAM.append(states_1[index_states_1[len(states_1)-1-i]])#(beamsize)\n",
    "\n",
    "                index[0][i]=index_states_1[len(states_1)-1-i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(1,b):#b:max_seq_len\n",
    "                SET=p[i,:]#(c,)\n",
    "                sum=[]\n",
    "                for j in range(c):#c:embedding_size\n",
    "                    for m in BEAM:\n",
    "                        sum.append(SET[j]+m)\n",
    "\n",
    "\n",
    "                sort_sum=np.argsort(sum)\n",
    "                kk=0\n",
    "                for k in range(len(sum)):\n",
    "                    #print \"i is\",i,\"k is\",k\n",
    "\n",
    "                    if kk==beamsize:\n",
    "                        break\n",
    "                    if k==0:\n",
    "                        BEAM=[]\n",
    "                    #print \"len(sum)\",len(sum),\"k\",k,\"shape_sort_sum\",np.shape(sort_sum)\n",
    "                    index_sum=sort_sum[len(sum)-1-k]\n",
    "\n",
    "                    aa=(index_sum+1)/beamsize#5 6/2=3\n",
    "                    bb=(index_sum+1)%beamsize\n",
    "                    if bb!=0:\n",
    "\n",
    "                        if aa!=30 and index[i-1][bb-1]!=30 and abs(index[i-1][bb-1]-aa)>1:\n",
    "                            continue\n",
    "                        else:\n",
    "                            index[i][kk]=aa\n",
    "                            mask[i][kk]=bb-1\n",
    "                            kk=kk+1\n",
    "                            BEAM.append(sum[sort_sum[len(sum)-1-k]])\n",
    "                            #print \"k:\",k,\"kk:\",kk,\"shape_BEAM:\",np.shape(BEAM)\n",
    "                    if bb==0:\n",
    "                        if (aa-1)!=30 and index[i-1][beamsize-1]!=30 and abs(index[i-1][beamsize-1]-aa+1)>1:\n",
    "                            continue\n",
    "                        else:\n",
    "                            index[i][kk]=aa-1\n",
    "                            mask[i][kk]=beamsize-1\n",
    "                            kk=kk+1\n",
    "                            BEAM.append(sum[sort_sum[len(sum)-1-k]])\n",
    "                            #print \"k:\",k,\"kk:\",kk,\"shape_BEAM:\",np.shape(BEAM)\n",
    "\n",
    "                #print \"shape_BEAM:\",np.shape(BEAM)\n",
    "\n",
    "\n",
    "                BEAM2[i]=BEAM\n",
    "                #print \"shape_BEAM2:\",np.shape(BEAM2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #print \"BEAM2 is\",BEAM2#scores\n",
    "\n",
    "            #print index,\"index_shape:\",np.shape(index)\n",
    "\n",
    "            index2=index\n",
    "            for k in range(beamsize): \n",
    "                index2[b-2][k]=index[b-2][mask[b-1][k]]\n",
    "                mask[b-2][k]=mask[b-2][mask[b-1][k]]\n",
    "            for i in range(b-2):\n",
    "                for k in range(beamsize):\n",
    "                    index2[b-3-i][k]=index[b-3-i][mask[b-2-i][k]]\n",
    "                    mask[b-3-i][k]=mask[b-3-i][mask[b-1-i][k]]\n",
    "            #print \"index2 is\",index2#path\n",
    "\n",
    "            index3[t]=index2\n",
    "            BEAM3[t]=BEAM2\n",
    "        yinsu_size=75\n",
    "        #print \"index3 is\",index3,\"BEAM3 is\",BEAM3\n",
    "        #print \"shape_index3:\",np.shape(index3),\"shape_BEAM3:\",np.shape(BEAM3)\n",
    "        index_final=np.array(index3)[:,:,0]\n",
    "        BEAM_final=np.array(BEAM3)[:,:,0]\n",
    "        #add\n",
    "        index_model4=index_final\n",
    "        voiced_target=[[0 for j in range(y)]for i in range(x)]\n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                if index_model4[i][j]==z-1:\n",
    "                    index_model4[i][j]=0\n",
    "                else:\n",
    "                    #index_model4[i][j] += 1\n",
    "                    index_model4[i][j]=(((index_final[i][j]+1)/yinsu_size)+1)\n",
    "                    voiced_target[i][j]=1\n",
    "            \n",
    "        print \"index_model4:\",np.shape(index_model4),index_model4\n",
    "        #print \"voiced_target:\",type(voiced_target),voiced_target\n",
    "\n",
    "\n",
    "\n",
    "        #add end\n",
    "        #print index_final,np.shape(index_final)\n",
    "        yinsudui=[[]for t in range(x)]\n",
    "        duration=[[]for t in range(x)]\n",
    "        len_yinsudui=[[]for t in range(x)]\n",
    "        for t in range(x):\n",
    "            yinsudui[t].append(index_final[t][0])\n",
    "        d=1\n",
    "        for t in range(x):\n",
    "            for j in range(1,y):\n",
    "\n",
    "                if index_final[t][j]!=index_final[t][j-1]:\n",
    "\n",
    "                    yinsudui[t].append(index_final[t][j])\n",
    "                    duration[t].append(d)\n",
    "                    d=1\n",
    "                else:\n",
    "                    d=d+1\n",
    "            duration[t].append(d)\n",
    "\n",
    "        for t in range(x):\n",
    "            len_yinsudui[t]=len(yinsudui[t])\n",
    "        for t in range(x):\n",
    "            for j in range(len_yinsudui[t]):\n",
    "                if yinsudui[t][j]==z-1:\n",
    "                    yinsudui[t].remove(z-1)\n",
    "                    duration[t].remove(duration[t][j])\n",
    "        #print \"duration is\",duration,\"shape_duration is\",np.shape(duration)\n",
    "        #print \"yinsudui is\",yinsudui,\"shape_yinsudui is\",np.shape(yinsudui)\n",
    "        #print \"target_values is\",target_values,\"shape_target_values is\",np.shape(target_values)       \n",
    "        leijia=0\n",
    "        \n",
    "#         for t in range(x):\n",
    "#             for j in range(len_yinsudui[t]):\n",
    "#                 print \"len_yinsudui[t]\",len_yinsudui[t]\n",
    "#                 yinsudui[t][j]=np.int(yinsudui[t][j])\n",
    "                \n",
    "#                 print leijia,yinsudui[t][j]\n",
    "#                 print len(target_values)\n",
    "#                 yinsudui2[t].append(target_values[leijia+yinsudui[t][j]])\n",
    "            \n",
    "#             leijia=leijia+len_yinsudui[t]-1\n",
    "#         print \"yinsudui2 is\",yinsudui2,\"shape_yinsudui2 is\",np.shape(yinsudui2)\n",
    "        \n",
    "        #yinsudui_size=yinsu_size*yinsu_size\n",
    "        #\n",
    "        yinsu=[[]for t in range(x)]\n",
    "        yinsu_seq_len=[0 for t in range(x)]\n",
    "        for t in range(x):\n",
    "            for j in range(len_yinsudui[t]):\n",
    "                yinsu[t].append((yinsudui[t][j]/yinsu_size)+1)\n",
    "            yinsu[t].append(yinsudui[t][len_yinsudui[t]-1]%yinsu_size)\n",
    "            yinsu_seq_len[t]=len(yinsu[t])\n",
    "            \n",
    "        #print \"yinsu is\",yinsu,\"shape_yinsu is\",np.shape(yinsu)\n",
    "        #print \"yinsu_seq_len is\",yinsu_seq_len\n",
    "\n",
    "        #\n",
    "        duration2=[[]for t in range(x)]\n",
    "        for t in range(x):\n",
    "            duration2[t].append(duration[t][0]/2)\n",
    "        for t in range(x):\n",
    "            for j in range(1,len_yinsudui[t]):\n",
    "                duration2[t].append((duration[t][j]+duration[t][j-1])/2)\n",
    "        for t in range(x):\n",
    "            duration2[t].append(duration[t][len_yinsudui[t]-1]/2)\n",
    "        #print \"duration2 is\",duration2,\"shape_duration2 is\",np.shape(duration2) \n",
    "        # duration=[[0 for i in range(z-1)]for t in range(x)]\n",
    "        # for t in range(x):\n",
    "        #     for i in range(z-1):\n",
    "        #         for j in range(y):\n",
    "        #             if index_final[t][j]==i:\n",
    "        #                 duration[t][i]=duration[t][i]+1\n",
    "        # print \"duration is\",duration,\"shape_duration is\",np.shape(duration)\n",
    "        num_buckets=10\n",
    "        #mean_duration=np.mean(duration,1)\n",
    "        max_duration2_pre=[0 for t in range(x)]\n",
    "        min_duration2_pre=[0 for t in range(x)]\n",
    "        for t in range(x):\n",
    "            max_duration2_pre[t]=np.max(duration2[t])\n",
    "            min_duration2_pre[t]=np.min(duration2[t])\n",
    "        max_duration2=np.max(max_duration2_pre)\n",
    "        min_duration2=np.min(min_duration2_pre)\n",
    "        #print max_duration2,min_duration2\n",
    "        buckets=[0 for i in range(num_buckets)]\n",
    "        \n",
    "        interval=(max_duration2-min_duration2)/num_buckets\n",
    "        for i in range(num_buckets):\n",
    "            buckets[i]=buckets[i]+i*interval\n",
    "        #print \"buckets is\",buckets,\"shape_buckets is\",np.shape(buckets)\n",
    "        len_yinsu=[0 for t in range(x)]\n",
    "        for t in range(x):\n",
    "            len_yinsu[t]=len(yinsu[t])\n",
    "        duration_buckets=[[0 for i in range(len_yinsu[t])]for t in range(x)]\n",
    "        for t in range(x):\n",
    "            for i in range(len_yinsu[t]):\n",
    "                for k in range(num_buckets):\n",
    "                    if duration2[t][i]>=buckets[num_buckets-k-1]:\n",
    "\n",
    "                        duration_buckets[t][i]=num_buckets-k#jia le 1\n",
    "                        break\n",
    "        print \"duration_buckets is\",duration_buckets,\"shape_duration_buckets is\",np.shape(duration_buckets)\n",
    "        max_yinsu_seq_len=np.max(yinsu_seq_len)\n",
    "        for t in range(x):\n",
    "            for i in range(max_yinsu_seq_len-len(yinsu[t])):\n",
    "                yinsu[t].append(0)\n",
    "                duration_buckets[t].append(0)\n",
    "        #print \"yinsu is \",yinsu,\"yinsu_seq_len is \",yinsu_seq_len,\"duration_buckets is \",duration_buckets\n",
    "        print \"voiced_target:\",type(voiced_target),voiced_target\n",
    "        %store yinsu\n",
    "        %store yinsu_seq_len\n",
    "        %store duration_buckets\n",
    "        %store index_model4\n",
    "        %store voiced_target\n",
    "        \n",
    "        #2,30\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
