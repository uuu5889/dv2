{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the final\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"/deepvoice/deepvoice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named utils.dataset_utils",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8ea8d698089e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrapheme_to_phoneme\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGraphemeToPhoneme\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named utils.dataset_utils"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils.dataset_utils import build_dataset\n",
    "from models.grapheme_to_phoneme import GraphemeToPhoneme\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tqdm import *\n",
    "from __future__ import division\n",
    "\n",
    "from compiler.ast import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_parameters = {\n",
    "    \"lr\": 0.001,\n",
    "    \"decay_steps\": 1000,\n",
    "    \"decay_rate\": 0.85,\n",
    "    \"dropout_prob\": 0.95\n",
    "}\n",
    "\n",
    "model_parameters = {\n",
    "  #embedding_size\": 50,\n",
    "  \"num_units\": 30,#随便\n",
    "  \"num_layers\": 3,\n",
    "  \"num_beams\": 5\n",
    "}\n",
    "\n",
    "\n",
    "end_token = 75\n",
    "\n",
    "num_steps = 1 #5\n",
    "\n",
    "save_energy = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r words_final2\n",
    "%store -r words_len_final2\n",
    "metadata_file = \"../../deepvoice2/cmu/cmu.pkl\"\n",
    "train_file = \"../../deepvoice2/cmu/cmu_data.npz\"\n",
    "train_file2 = \"../../deepvoice2/cmu/VCTK_data2.npz\"\n",
    "\n",
    "with open(metadata_file, \"r\") as read_file:\n",
    "    meta = pickle.load(read_file)\n",
    "char2id = meta[\"char2id\"]\n",
    "id2char = meta[\"id2char\"]\n",
    "phoneme2id = meta[\"phoneme2id\"]\n",
    "id2phoneme = meta[\"id2phoneme\"]\n",
    "\n",
    "input_vocab_size = len(char2id)#35\n",
    "output_vocab_size= len(phoneme2id)#76\n",
    "\n",
    "end_token = phoneme2id[\"<eos>\"]\n",
    "\n",
    "data = np.load(train_file)\n",
    "data2=np.load(train_file2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    characters = tf.placeholder(tf.int32, [None, None])\n",
    "    characters_seq_len = tf.placeholder(tf.int32, [None])\n",
    "    phonemes = tf.placeholder(tf.int32, [None, None])\n",
    "    phonemes_seq_len = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    prediction_characters = tf.placeholder(tf.int32, [None, None])\n",
    "    prediction_characters_seq_len = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    model = GraphemeToPhoneme(input_vocab_size, output_vocab_size, end_token, model_parameters)\n",
    "    \n",
    "    #train_op_tf, loss_tf, global_step_tf, summary_tf, decoder_output_tf ,prediction_tf= model.build_train_operations(\n",
    "    train_op_tf, loss_tf, global_step_tf, summary_tf, decoder_output_tf = model.build_train_operations(\n",
    "        characters, characters_seq_len, phonemes, phonemes_seq_len, train_parameters\n",
    "    )\n",
    "    \n",
    "    prediction_tf,prediction_seq_len_tf = model.build_prediction(prediction_characters, prediction_characters_seq_len, True)\n",
    "    \n",
    "\n",
    "\n",
    "    train_writer = tf.summary.FileWriter('../log/train_grapheme_to_phoneme_model_notebook/train', sess.graph)\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "   \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=3, keep_checkpoint_every_n_hours=3)\n",
    "    train=0\n",
    "    if train==0:\n",
    "        tf.add_to_collection('prediction',prediction_tf)\n",
    "        for _ in tqdm(xrange(num_steps)):\n",
    "            out = sess.run([\n",
    "                train_op_tf,\n",
    "                global_step_tf,\n",
    "                loss_tf,\n",
    "                summary_tf,\n",
    "                decoder_output_tf,\n",
    "            #prediction_tf\n",
    "            ], feed_dict={\n",
    "                characters: data[\"X\"],\n",
    "                characters_seq_len: data[\"X_seq_len\"],\n",
    "                phonemes: data[\"Y\"],\n",
    "                phonemes_seq_len: data[\"Y_seq_len\"]\n",
    "            })\n",
    "            _, global_step, loss, summary, decoder_output= out\n",
    "        #,prediction\n",
    "            train_file2 = \"../../deepvoice2/cmu/VCTK_data.npz\"\n",
    "            data2 = np.load(train_file2)\n",
    "        #prediction=sess.run([prediction_tf],feed_dict={prediction_characters:data2[\"X\"],\n",
    "        #                                               prediction_characters_seq_len:data2[\"X_seq_len\"]})\n",
    "\n",
    "            train_writer.add_summary(summary, global_step)\n",
    "\n",
    "        # detect gradient explosion\n",
    "            if loss > 1e8 and global_step > 500:\n",
    "                print('loss exploded')\n",
    "                break\n",
    "\n",
    "        #if global_step % save_energy == 0 and global_step != 0:\n",
    "\n",
    "            print('saving weights')\n",
    "        #print np.shape(prediction),prediction\n",
    "            print(loss)\n",
    "            #在测试集上算模型精确度？\n",
    "            #correct_prediction = tf.equal(tf.argmax(decoder_output_tf, 1), tf.argmax(phonemes, 1))\n",
    "            #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            #print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]})\n",
    "            #print \"Accuracy:\", accuracy.eval({characters:data[\"X\"],characters_seq_len:...,phonemes: data[\"Y\"],...:...})\n",
    "            if not os.path.exists('../weights/train_grapheme_to_phoneme_model_notebook/'):\n",
    "                os.makedirs('../weights/train_grapheme_to_phoneme_model_notebook/')\n",
    "            saver.save(sess, '../weights/train_grapheme_to_phoneme_model_notebook/model.ckpt', global_step=global_step)\n",
    "             \n",
    "        \n",
    "          \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    else:\n",
    "        \n",
    "        saver.restore(sess, '../weights/train_grapheme_to_phoneme_model_notebook/model.ckpt-1')\n",
    "        graph = tf.get_default_graph()\n",
    "        for i in tqdm(range(1)):\n",
    "            prediction,prediction_seq_len=sess.run([prediction_tf,prediction_seq_len_tf],\n",
    "                                                   feed_dict={prediction_characters:words_final2,\n",
    "                                                           prediction_characters_seq_len:words_len_final2})\n",
    "        print prediction,np.shape(prediction),prediction_seq_len\n",
    "        #print data2[\"X\"],np.shape(data2[\"X\"]),data2[\"X_seq_len\"],np.shape(data2[\"X_seq_len\"])\n",
    "        %store prediction\n",
    "            \n",
    "        \n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
